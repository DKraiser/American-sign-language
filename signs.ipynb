{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd9610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from typing import Any\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.functional as fun\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1969b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = kagglehub.dataset_download(\"kapillondhe/american-sign-language\")\n",
    "path += '\\\\ASL_Dataset'\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4104903d",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6036edbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths(root: str, n: int) -> list[str]:\n",
    "    paths = list()\n",
    "    dont_stop = (n == -1)\n",
    "    labels = os.listdir(root)\n",
    "    for label in labels:\n",
    "        for imgname in os.listdir(f'{root}\\\\{label}'):\n",
    "            paths.append(f'{root}\\\\{label}\\\\{imgname}')\n",
    "            n -= 1\n",
    "            if not dont_stop and n < 0:\n",
    "                break\n",
    "            \n",
    "        if not dont_stop and n < 0:\n",
    "            break\n",
    "        \n",
    "    return paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ff7e1c",
   "metadata": {},
   "source": [
    "### Data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d51f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_balance(root: str) -> dict[str, int]:\n",
    "    labels = set()\n",
    "    count_of_labels = dict()\n",
    "    \n",
    "    for data_class in os.listdir(root):\n",
    "        labels.add(data_class)\n",
    "    \n",
    "    for label in labels:\n",
    "        count_of_labels[label] = len(os.listdir(f'{root}\\\\{label}')) \n",
    "    \n",
    "    return count_of_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6489d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = data_balance(f'{path}\\\\Train')\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.set_title(\"Class distribution\")\n",
    "ax.grid(True, 'major', 'y')\n",
    "ax.bar(list(count.keys()), list(count.values()), align='center', width=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be9674e",
   "metadata": {},
   "source": [
    "### Image resolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db368f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolutions(root) -> set[tuple[int, int]]:\n",
    "    paths = get_paths(root, -1)  \n",
    "    resolutions = set()\n",
    "    for imgpath in paths:\n",
    "        img = Image.open(imgpath)\n",
    "        resolutions.add(img.size)\n",
    "        \n",
    "    return resolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ee545c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Resolutions in training set: {resolutions(f'{path}\\\\Train')}')\n",
    "print(f'Resolutions in evaluation set: {resolutions(f'{path}\\\\Test')}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0341d349",
   "metadata": {},
   "source": [
    "### Corrupted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7c7fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupted(root) -> list:\n",
    "    corrupted = list()\n",
    "    paths = get_paths(root, 2000)  \n",
    "\n",
    "    for p in paths:\n",
    "        try:\n",
    "            Image.open(p).verify()\n",
    "        except:\n",
    "            corrupted.append(p)\n",
    "    \n",
    "    return corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076f7479",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corrupted = corrupted(f'{path}\\\\Train')\n",
    "test_corrupted = corrupted(f'{path}\\\\Test')\n",
    "\n",
    "print(f'Count of corrupted images in training set: {len(train_corrupted)} ({train_corrupted})')\n",
    "print(f'Count of corrupted images in evaluating set: {len(test_corrupted)} ({test_corrupted})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120dc0cb",
   "metadata": {},
   "source": [
    "### Color channels\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402003f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channels(root: str) -> set[str]:\n",
    "    paths = get_paths(root, 2000)\n",
    "    channels = set()\n",
    "    \n",
    "    for p in paths:\n",
    "        img = Image.open(p)\n",
    "        channels.add(img.getbands())\n",
    "        \n",
    "    return channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd5c5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_channels = get_channels(f'{path}\\\\Train')\n",
    "test_channels = get_channels(f'{path}\\\\Test')\n",
    "\n",
    "print(f'Count of color schemas in training set: {len(train_channels)} ({train_channels})')\n",
    "print(f'Count of color schemas in evaluating set: {len(test_channels)} ({test_channels})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19de16ed",
   "metadata": {},
   "source": [
    "### Pixel intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232f82a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_intensities(root: str) -> list[float]:\n",
    "    paths = get_paths(root, 1000)  \n",
    "    intensities = list()\n",
    "    for p in paths:\n",
    "        img = Image.open(p).convert('L')\n",
    "        intensities.append(float(np.mean(img)))\n",
    "    \n",
    "    return intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5530f3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_intensities = get_average_intensities(f'{path}\\\\Train')\n",
    "test_intensities = get_average_intensities(f'{path}\\\\Test')\n",
    "\n",
    "print('Training set')\n",
    "print(f'Mean: {float(round(np.mean(train_intensities), 3))}') \n",
    "print(f'Std: {float(round(np.std(train_intensities), 3))}')\n",
    "print(f'Range (min - max): {round(min(train_intensities), 3)} - {round(max(train_intensities), 3)}')\n",
    "print()\n",
    "print('Evaluating set')\n",
    "print(f'Mean: {float(round(np.mean(test_intensities), 3))}') \n",
    "print(f'Std: {float(round(np.std(test_intensities), 3))}')\n",
    "print(f'Range (min - max): {round(min(test_intensities), 3)} - {round(max(test_intensities), 3)}')\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.set_title(\"Average pixel intensities\")\n",
    "ax1.grid(True, 'major', 'y')\n",
    "ax1.hist([train_intensities, test_intensities], bins=30, label=['Training set', 'Evaluating set'])\n",
    "ax1.legend()\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.set_title(\"Average pixel intensities\")\n",
    "ax2.grid(True, 'both', 'x')\n",
    "ax2.boxplot([train_intensities, test_intensities], orientation='horizontal', tick_labels=['Training set', 'Evaluating set'])\n",
    "\n",
    "fig.subplots_adjust(wspace=0.25)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f33125",
   "metadata": {},
   "source": [
    "### Contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb4c79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contrasts(root: str) -> list[float]:\n",
    "    paths = get_paths(root, 2000)  \n",
    "    contrasts = list()\n",
    "    for p in paths:\n",
    "        img = Image.open(p).convert('L')\n",
    "        arr = np.array(img, dtype=np.float32)\n",
    "        min_l = arr.min()\n",
    "        max_l = arr.max()\n",
    "\n",
    "        if max_l + min_l == 0:\n",
    "            contrasts.append(0.0)\n",
    "        else:\n",
    "            contrasts.append((max_l - min_l) / (max_l + min_l))   \n",
    "        \n",
    "    return contrasts    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40fa4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_contrasts = get_contrasts(f'{path}\\\\Train')\n",
    "test_contrasts = get_contrasts(f'{path}\\\\Test')\n",
    "\n",
    "print('Training set')\n",
    "print(f'Mean: {float(round(np.mean(train_contrasts), 3))}') \n",
    "print(f'Std: {float(round(np.std(train_contrasts), 3))}')\n",
    "print(f'Range (min - max): {round(min(train_contrasts), 3)} - {round(max(train_contrasts), 3)}')\n",
    "print()\n",
    "print('Evaluating set')\n",
    "print(f'Mean: {float(round(np.mean(test_contrasts), 3))}') \n",
    "print(f'Std: {float(round(np.std(test_contrasts), 3))}')\n",
    "print(f'Range (min - max): {round(min(test_contrasts), 3)} - {round(max(test_contrasts), 3)}')\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.set_title(\"Contrasts\")\n",
    "ax1.grid(True, 'major', 'y')\n",
    "ax1.hist([train_contrasts, test_contrasts], bins=30, label=['Training set', 'Evaluating set'])\n",
    "ax1.legend()\n",
    "\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.set_title(\"Contrasts\")\n",
    "ax2.grid(True, 'both', 'x')\n",
    "ax2.boxplot([train_contrasts, test_contrasts], orientation='horizontal', tick_labels=['Training set', 'Evaluating set'])\n",
    "\n",
    "fig.subplots_adjust(wspace=0.25)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a3b580",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c9c3c8",
   "metadata": {},
   "source": [
    "After the data exploration it was investigated that data:\n",
    "- Are well distributed\n",
    "- Have the same size\n",
    "- Test data are in average brighter than the evaluating data\n",
    "- All data are in RGB mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c81558",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(\n",
    "        brightness=0.3,\n",
    "        contrast=0.3,\n",
    "        saturation=0.3,\n",
    "        hue=0.05\n",
    "    ),\n",
    "    transforms.GaussianBlur(kernel_size=3),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c747d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.ImageFolder(root=f'{path}\\\\Train', transform=train_transform)\n",
    "test_dataset = torchvision.datasets.ImageFolder(root=f'{path}\\\\Test', transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775b0a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_imgs = list()\n",
    "fig, ax = plt.subplots(5, 5, figsize=(10, 10))\n",
    "for i in range(25):\n",
    "    img, label = train_dataset[i]\n",
    "    img2 = img.permute(1, 2, 0).numpy() \n",
    "    aug_imgs.append(img2)\n",
    "    ax[i // 5][i % 5].imshow(img2)\n",
    "    ax[i // 5][i % 5].get_xaxis().set_visible(False)\n",
    "    ax[i // 5][i % 5].get_yaxis().set_visible(False)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57aa7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(root: str) -> list[str]:\n",
    "    return os.listdir(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cba4bd",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b986a40",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- Loss (train/val)\n",
    "- Confusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb38f94",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4864f73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, config: dict[str, Any]):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential()\n",
    "        \n",
    "        output_w = None\n",
    "        output_h = None\n",
    "        \n",
    "        last_l = None\n",
    "            \n",
    "        for l in range(config['count_of_conv_layers']):\n",
    "            self.main.add_module(f'Conv_{l}',\n",
    "                nn.Conv2d(\n",
    "                    in_channels=3 if l == 0 else config['l0_filters'] * (2 ** (l - 1)),\n",
    "                    kernel_size=config['conv_kernel_size'],\n",
    "                    padding=config['padding'],\n",
    "                    out_channels=config['l0_filters'] * (2 ** l)\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            self.main.add_module(f'ConvLeakyReLU_{l}', nn.LeakyReLU())\n",
    "            \n",
    "            self.main.add_module(f'MaxPooling_{l}',\n",
    "                nn.MaxPool2d(kernel_size=config['max_pool_kernel_size'])               \n",
    "            )\n",
    "            \n",
    "            self.main.add_module(f'DropoutConv_{l}', nn.Dropout(config['dropout']))\n",
    "            \n",
    "            output_w = int((int((224 if l == 0 else output_w) + 2 * config['padding'] - 1 * (config['conv_kernel_size'] - 1) - 1) + 1) / config['max_pool_kernel_size'])\n",
    "            output_h = int((int((224 if l == 0 else output_h) + 2 * config['padding'] - 1 * (config['conv_kernel_size'] - 1) - 1) + 1)/ config['max_pool_kernel_size'])\n",
    "            \n",
    "            last_l = l\n",
    "                \n",
    "        self.main.add_module('Flatten', nn.Flatten())     \n",
    "                     \n",
    "        self.main.add_module('Linear_Hidden', \n",
    "            nn.Linear(output_w * output_h * (config['l0_filters'] * (2 ** last_l)), config['n_hidden'])\n",
    "        )\n",
    "        self.main.add_module('LeakyReLU_Hidden', nn.LeakyReLU())\n",
    "        self.main.add_module('Dropout_Hidden', nn.Dropout())\n",
    "        \n",
    "        self.main.add_module('Linear_Output', nn.Linear(config['n_hidden'], config['n_out']))   \n",
    "        self.main.add_module('Sigmoid_Output', nn.Sigmoid())\n",
    "              \n",
    "    def forward(self, x):\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b123157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    device: str\n",
    "    config: dict[str, Any]\n",
    "    model: Model\n",
    "    train_dataloader: torch.utils.data.DataLoader\n",
    "    test_dataloader: torch.utils.data.DataLoader\n",
    "    \n",
    "    def __init__(self, config: dict[str, Any]):\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.config = config\n",
    "        self.model = Model(config).to(self.device)\n",
    "        self.train_dataloader = torch.utils.data.DataLoader(batch_size=self.config['batch_size'], shuffle=True, dataset=train_dataset, num_workers=2)\n",
    "        self.test_dataloader = torch.utils.data.DataLoader(batch_size=self.config['batch_size'], shuffle=True, dataset=test_dataset, num_workers=2)\n",
    "    \n",
    "    def fit(self):\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "        opt = torch.optim.Adam(params=self.model.parameters(), lr=self.config[\"learning_rate\"], weight_decay=self.config[\"weight_decay\"])\n",
    "        for epoch in range(self.config[\"epochs\"]):\n",
    "            log = dict()\n",
    "            self.train(loss, opt, epoch, log)\n",
    "            self.val(loss, epoch, log)\n",
    "\n",
    "            wandb.log({\n",
    "                \"train_loss\": log[\"train_avg_loss\"],\n",
    "                \"val_loss\": log[\"val_avg_loss\"],\n",
    "                \"accuracy\": log[\"accuracy\"],\n",
    "                \"precision\": log[\"precision\"],\n",
    "                \"recall\": log[\"recall\"]\n",
    "            })\n",
    "\n",
    "    def train(self, loss, opt, epoch, log):\n",
    "        total_loss = 0\n",
    "        with tqdm(self.train_dataloader, desc=f\"Train {epoch}: \") as progress:\n",
    "            for x, y in progress:\n",
    "                batch_size = x.size()[0]\n",
    "                x = x.to(self.device)\n",
    "                target = torch.zeros(size=(batch_size, self.config['n_out']), dtype=float)\n",
    "                target[:, y] = 1.0\n",
    "                target = target.to(self.device)\n",
    "\n",
    "                predicted = self.model(x)\n",
    "                # print(f'Size of prediction tensor: {predicted.size()} ({predicted})')\n",
    "                # print(f'Size of correct truth tensor: {target.size()} ({target})')\n",
    "                l = loss(predicted, target)\n",
    "\n",
    "                opt.zero_grad()\n",
    "                l.backward()\n",
    "                opt.step()\n",
    "\n",
    "                total_loss += l.item()\n",
    "\n",
    "            avg_loss = total_loss / len(self.train_dataloader)\n",
    "            log[\"train_avg_loss\"] = avg_loss\n",
    "\n",
    "    def val(self, loss, epoch, log):\n",
    "        total_loss = 0\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "\n",
    "        with tqdm(self.test_dataloader, desc=f\"Val {epoch}: \") as progress:\n",
    "            with torch.no_grad():\n",
    "                for x, y in progress:\n",
    "                    batch_size = x.size()[0]\n",
    "                    x = x.to(self.device)\n",
    "                    target = torch.zeros(size=(batch_size, self.config['n_out']), dtype=float)\n",
    "                    target[:, y] = 1.0\n",
    "                    target = target.to(self.device)\n",
    "\n",
    "                    predicted = self.model(x)\n",
    "                    l = loss(predicted, target)\n",
    "                    preds_np = predicted.argmax(dim=1).cpu().numpy()\n",
    "                    targets_np = y.cpu().numpy()\n",
    "\n",
    "                    all_preds.append(preds_np)\n",
    "                    all_targets.append(targets_np)\n",
    "\n",
    "                    total_loss += l.item()\n",
    "                    \n",
    "            \n",
    "            all_preds = np.concatenate(all_preds)\n",
    "            all_targets = np.concatenate(all_targets)\n",
    "            accuracy, precision, recall, _ = self.compute_metrics(all_preds, all_targets)\n",
    "            \n",
    "            avg_loss = total_loss / len(self.test_dataloader)\n",
    "            \n",
    "            log[\"val_avg_loss\"] = avg_loss\n",
    "            log[\"accuracy\"] = accuracy\n",
    "            log[\"precision\"] = precision\n",
    "            log[\"recall\"] = recall\n",
    "\n",
    "    def compute_metrics(self, all_preds: np.ndarray, all_targets: np.ndarray) -> tuple[float, float, float, np.ndarray]:\n",
    "        num_classes = self.config[\"n_out\"] \n",
    "        \n",
    "        conf = np.zeros((num_classes, num_classes), dtype=np.int64)\n",
    "        for t, p in zip(all_targets, all_preds):\n",
    "            conf[t, p] += 1\n",
    "\n",
    "        accuracy = conf.trace() / conf.sum()\n",
    "\n",
    "        precision = np.zeros(num_classes)\n",
    "        recall = np.zeros(num_classes)\n",
    "\n",
    "        for c in range(num_classes):\n",
    "            tp = conf[c, c]\n",
    "            fp = conf[:, c].sum() - tp\n",
    "            fn = conf[c, :].sum() - tp\n",
    "\n",
    "            precision[c] = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "            recall[c] = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "\n",
    "        precision = precision.mean()\n",
    "        recall = recall.mean()  \n",
    "        \n",
    "        return (accuracy, precision, recall, conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f94152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'count_of_conv_layers': 4,    \n",
    "    'conv_kernel_size': 3,\n",
    "    'l0_filters': 32, \n",
    "    'padding': 1,\n",
    "    'max_pool_kernel_size': 2,\n",
    "    \n",
    "    'n_hidden': 512,\n",
    "    'n_out': len(get_labels(f'{path}\\\\Test')),\n",
    "    \n",
    "    'batch_size': 52,\n",
    "    'dropout': 0.3,\n",
    "    'epochs': 200,\n",
    "    'learning_rate': 10e-2,\n",
    "    'weight_decay': 10e-4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18a21f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project='Signs', config=config, reinit='finish_previous')\n",
    "exit_code = 0\n",
    "\n",
    "try:\n",
    "    agent = Agent(wandb.config)\n",
    "    agent.fit()\n",
    "    torch.save(agent.model.state_dict(), 'state.pt')\n",
    "    wandb.save('state.pt')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    exit_code = 1    \n",
    "    \n",
    "wandb.finish(exit_code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
